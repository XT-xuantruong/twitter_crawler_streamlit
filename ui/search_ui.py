import streamlit as st
from services.twitter_playwright import PlaywrightTwitterScraper
from utils.io import df_to_csv_bytes
from storage.db import save_records

def render_search_tab(cookie_meta):
    st.header("ğŸ” Twitter Search")

    query = st.text_input("Nháº­p tá»« khoÃ¡ tÃ¬m kiáº¿m", value="fake news", key="search_query")
    max_posts = st.number_input("Sá»‘ lÆ°á»£ng tá»‘i Ä‘a", min_value=10, max_value=2000, value=100, step=50, key="search_max")
    headless = st.checkbox("Headless", value=True, key="search_headless")

    if st.button("ğŸš€ Start Search", key="search_btn"):
        print("Starting search with cookie:", cookie_meta.get("cookies_path"))
        scraper = PlaywrightTwitterScraper(headless=headless, cookies_path=cookie_meta.get("cookies_path"))
        dfs = []
        for df, meta in scraper.search(query, limit=max_posts):
            dfs.append(df)

        if not dfs:
            st.warning("âŒ KhÃ´ng thu Ä‘Æ°á»£c dá»¯ liá»‡u.")
            return

        final_df = dfs[-1]
        st.success(f"âœ… Thu Ä‘Æ°á»£c {len(final_df)} bÃ i viáº¿t.")
        st.dataframe(final_df)

        # Xuáº¥t CSV
        csv_bytes = df_to_csv_bytes(final_df)
        st.download_button("ğŸ“¥ Download CSV", data=csv_bytes, file_name="tweets_search.csv", mime="text/csv")

        # LÆ°u DB
        save_records(final_df, table_name="tweets")
        st.info("ğŸ’¾ Dá»¯ liá»‡u Ä‘Ã£ lÆ°u vÃ o MySQL")
