import streamlit as st
from services.twitter_playwright import PlaywrightTwitterScraper
from utils.io import df_to_csv_bytes
from storage.db import save_records

def render_user_tab(cookie_meta):
    st.header("ğŸ‘¤ Crawl User Timeline")

    username = st.text_input("Nháº­p username (khÃ´ng cÃ³ @)", value="elonmusk", key="user_username")
    max_posts = st.number_input("Sá»‘ lÆ°á»£ng tá»‘i Ä‘a", min_value=10, max_value=2000, value=100, step=50, key="user_max")
    headless = st.checkbox("Headless", value=True, key="user_headless")

    if st.button("ğŸš€ Start Crawl User", key="user_btn"):
        scraper = PlaywrightTwitterScraper(headless=headless, cookies_path=cookie_meta.get("cookies_path"))
        dfs = []
        for df, meta in scraper.user_tweets(username, limit=max_posts):
            dfs.append(df)

        if not dfs:
            st.warning("âŒ KhÃ´ng thu Ä‘Æ°á»£c dá»¯ liá»‡u.")
            return

        final_df = dfs[-1]
        st.success(f"âœ… Thu Ä‘Æ°á»£c {len(final_df)} bÃ i viáº¿t tá»« @{username}")
        st.dataframe(final_df)

        # Xuáº¥t CSV
        csv_bytes = df_to_csv_bytes(final_df)
        st.download_button("ğŸ“¥ Download CSV", data=csv_bytes, file_name=f"{username}_tweets.csv", mime="text/csv")

        # LÆ°u DB
        save_records(final_df, table_name="tweets")
        st.info("ğŸ’¾ Dá»¯ liá»‡u Ä‘Ã£ lÆ°u vÃ o MySQL")
